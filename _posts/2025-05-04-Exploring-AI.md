---
title: My First Week Exploring AI Tools, and More
categories: [Wha have I learned today?]
tags: [AI, NotebookLM, Cursor, Perplexity,Claude,Gemini, VS Code]
---

# My First Week Exploring AI Tools
Last week, I started watching the YouTube video [How I Use LLMs by Andrej Karpathy](https://www.youtube.com/watch?v=EWvNQjAaOHw), and it really helped me gain a better understanding of how AI works under the hood. I learned about different models and capabilities such as Web Search, Deep Search, and Deep Thinking.

I also began to understand the differences between various ChatGPT models and why some are called “O” models—turns out, the "O" stands for models designed for more advanced "thinking" tasks.

Here are a few key insights I took away:

* Thinking models (like the GPT-4 “O” series) are especially good at tasks like programming and math—great news for students and developers.

* Language models are essentially neural networks that work by communicating through tokens.

* For internet-based research, Karpathy recommends using Perplexity, as it’s been designed for that purpose longer than ChatGPT.

* Claude Sonnet stood out for its ability to generate app mockups and previews directly—something I found really useful and time-saving.

# NotebookLM – Mind-Blowing Simplicity
One tool Andrej mentioned that truly blew my mind was NotebookLM, a Google-based solution. It can take a PDF, turn it into a podcast, and even let you interrupt the audio to ask questions—how amazing is that?

It made me think: what if we could have real-time conversations with an AI about a book we’re reading—discussing ideas, asking questions, even testing comprehension? The future of learning feels incredibly exciting.

# Cursor – AI-Powered Coding Assistant
Next up: Cursor.

This was probably the most impressive tool I saw. It’s an all-in-one AI coding assistant that lets you create entire applications just by describing what you want. No need to copy code from ChatGPT, manually add dependencies, or debug setup errors—Cursor does it all.

I was left speechless. It’s the kind of tool that makes me rethink how I approach building apps from scratch.

# Handwriting Transcription – My First Attempt at Building Something
While watching the video, I couldn’t resist taking handwritten notes—I knew I’d need them later to remember all the insights. But then I wondered: “What if I could get my notes transcribed automatically using my PC camera?”

So, I paused the video and jumped into Replit (a platform I discovered thanks to my partner—more on that in a future post). I asked it to help me build a tool that could transcribe my handwriting in real time.

The result? Not great. It struggled a lot. I couldn’t even get a clear “Hello” transcribed. That experience made me realize how difficult it is to build a reliable handwriting recognition system, especially since everyone's handwriting is so different.

Now, I’m curious—does a tool like this already exist? I’ll be researching more to find out. And who knows? Maybe I’ll try to build one myself.
